from bs4 import BeautifulSoup
from urllib.request import urlopen
import urllib.request
import requests

import csv

adobe_oob = "https://helpx.adobe.com/security.html"

# query the website and return the html to the variable ‘adobe_page’
adobe_page = urlopen(adobe_oob)

# parse the html using beautiful soup and store in variable `adobe_soup`
adobe_soup = BeautifulSoup(adobe_page, 'html.parser')
data_adobe = []
table_adobe = adobe_soup.find('div', attrs={'class':'table parbase section'})
table_body_adobe = table_adobe.find('tbody')

rows_adobe = table_body_adobe.findAll('tr')
for row in rows_adobe:
    cols = row.find_all('td')
    cols = (ele.text.strip() for ele in cols)
    data_adobe.append(list(ele for ele in cols if ele))

data_adobe = list(filter(None, data_adobe))

for names in data_adobe:
    with open('C:\\Automation_OOB\\Backend_stuff\\adobe.txt', 'w', newline='', encoding='utf-8') as csv_file:
        writer = csv.writer(csv_file, delimiter=' ')
        writer.writerow(names)
    
print("Adobe Scraped...")
