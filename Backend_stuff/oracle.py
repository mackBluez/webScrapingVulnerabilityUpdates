import requests
from bs4 import BeautifulSoup
import csv

response = requests.get("https://www.oracle.com/technetwork/topics/security/alerts-086861.html")
soup = BeautifulSoup(response.text, "html.parser")
data_oracle = []
critical_oracle = soup.find('tbody')

rows = critical_oracle.findAll('tr')
for row in rows:
    cols = row.find_all('td')
    cols = [ele.text.strip() for ele in cols]
    data_oracle.append([ele for ele in cols if ele])



alerts_oracle = soup.findAll('table')[1]
alert_rows = alerts_oracle.findAll('tr')
for row in alert_rows:
    cols = row.find_all('td')
    cols = [ele.text.strip() for ele in cols]
    data_oracle.append(list(ele for ele in cols if ele))

data_oracle = list(filter(None, data_oracle))

for names in data_oracle:
    with open('C:\\Automation_OOB\\Backend_stuff\\oracle.txt', 'a') as csv_file:
        writer = csv.writer(csv_file)
        writer.writerow(names)

print("Oracle Scraped...")

