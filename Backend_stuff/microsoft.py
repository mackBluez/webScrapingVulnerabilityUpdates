#import modules
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import csv
import requests



#chrome driver
chrome_path = r"C:\Automation_OOB\Backend_stuff\chromedriver.exe"
driver = webdriver.Chrome(chrome_path)
driver.get("https://portal.msrc.microsoft.com/en-us/security-guidance")

#EULA Page code
delay1 = 10
try:
    myElem = WebDriverWait(driver, delay1).until(EC.presence_of_element_located((By.XPATH, """//*[@id="JelloWrapper"]/div[3]/div[2]/div/ui-view/form/input[1]""")))
except TimeoutException:
    print ("Loading took too much time!")

#click checkbox
driver.find_element_by_xpath("""//*[@id="JelloWrapper"]/div[3]/div[2]/div/ui-view/form/div[1]/label/input""").click()

#click accept
driver.find_element_by_xpath("""//*[@id="JelloWrapper"]/div[3]/div[2]/div/ui-view/form/input[1]""").click()

data_microsoft = []

#Main Page code
delay = 20 # seconds
try:
    myElem = WebDriverWait(driver, delay).until(EC.presence_of_element_located((By.XPATH, """//*[@id="JelloWrapper"]/div[3]/div[2]/div/ui-view/table[2]/tbody[5]/tr[1]/td[2]""")))
except TimeoutException:
    print ("Loading took too much time!")

vulns = driver.find_elements_by_xpath("""//*[@id="JelloWrapper"]/div[3]/div[2]/div/ui-view/table[2]/tbody[1]/tr[1]/td[1]""")


for vuln in vulns:
    data_microsoft.append(vuln.text)


#testing code for removing \n commented out
#for micros in data_microsoft:
#    micros.rstrip("\n")

#data_microsoft = list(filter("\n", data_microsoft))

#for names in data_microsoft:
with open('C:\\Automation_OOB\\Backend_stuff\\microsoft.txt', 'a') as csv_file:
    writer = csv.writer(csv_file, delimiter=' ')
    writer.writerow(data_microsoft)

print("Microsoft Scraped...")


driver.quit()
